{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe4e0db3-d3c6-4e2e-8455-cda99d9b6d26",
   "metadata": {},
   "source": [
    "## Convert PyTorch Model to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e5fade0-055f-44ac-99a9-f912a12b3821",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dnth/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "model = timm.create_model('convnext_xxlarge.clip_laion2b_soup_ft_in1k', pretrained=True)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aced3849-58a2-461b-a958-64ec378710ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from timm.utils.model import reparameterize_model\n",
    "model = reparameterize_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4ca92b4-bbcb-4b9e-827c-2334af37ed3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.onnx\n",
    "torch.onnx.export(model,\n",
    "                 torch.rand(1, 3, 224, 224, requires_grad=True),\n",
    "                 \"convnext_xxlarge.clip_laion2b_soup_ft_in1k.onnx\",\n",
    "                 export_params=True,\n",
    "                 opset_version=16,\n",
    "                 do_constant_folding=True,\n",
    "                 input_names=['input'],\n",
    "                 output_names=['output'], \n",
    "                 dynamic_axes={'input' : {0 : 'batch_size'},   \n",
    "                               'output' : {0 : 'batch_size'}}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc5b9b6-25e8-4798-8674-490661bb95f4",
   "metadata": {},
   "source": [
    "## Inference using ONNX Runtime on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49d78b1f-fee6-4178-aecb-06817da4887f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "from PIL import Image\n",
    "from urllib.request import urlopen\n",
    "\n",
    "#define the priority order for the execution providers\n",
    "\n",
    "# prefer CUDA Execution Provider over CPU Execution Provider\n",
    "EP_list = ['CUDAExecutionProvider', 'CPUExecutionProvider', 'OpenVINOExecutionProvider']\n",
    "\n",
    "# Load an image\n",
    "img = Image.open(urlopen('https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png'))\n",
    "img = img.convert('RGB')\n",
    "img = img.resize((224, 224))\n",
    "img_np = np.array(img).astype(np.float32)\n",
    "\n",
    "# Load ONNX model\n",
    "session = ort.InferenceSession(\"convnext_xxlarge.clip_laion2b_soup_ft_in1k.onnx\", providers=EP_list)\n",
    "session.set_providers(['CPUExecutionProvider'])\n",
    "\n",
    "# Convert data to the shape the ONNX model expects\n",
    "input_data = np.transpose(img_np, (2, 0, 1))  # Convert to (C, H, W)\n",
    "input_data = np.expand_dims(input_data, axis=0)  # Add a batch dimension\n",
    "\n",
    "# Get input name from the model\n",
    "input_name = session.get_inputs()[0].name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d949c3b-8e81-4755-a0fb-fe3dbe453b7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "957 ms ± 211 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# Perform inference\n",
    "output = session.run(None, {input_name: input_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e2f4c8f-ca56-4ff4-8be4-0b4597b440fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract output data (assuming model has a single output)\n",
    "output = session.run(None, {input_name: input_data})\n",
    "output_data = output[0]\n",
    "output_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef468a7b-1385-4b5b-aa65-d4c56ab57879",
   "metadata": {},
   "source": [
    "## ONNX Runtime with CUDA Execution Provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab9da3a1-1ae0-4525-bea2-15ed72de7d15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load ONNX model\n",
    "session = ort.InferenceSession(\"convnext_xxlarge.clip_laion2b_soup_ft_in1k.onnx\", providers=EP_list)\n",
    "session.set_providers(['CUDAExecutionProvider'])\n",
    "\n",
    "# Convert data to the shape the ONNX model expects\n",
    "input_data = np.transpose(img_np, (2, 0, 1))  # Convert to (C, H, W)\n",
    "input_data = np.expand_dims(input_data, axis=0)  # Add a batch dimension\n",
    "\n",
    "input_data.shape\n",
    "\n",
    "# Get input name from the model\n",
    "input_name = session.get_inputs()[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd8376b9-9ddc-4161-a4fb-1191292a515a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "877 ms ± 230 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# Perform inference\n",
    "output = session.run(None, {input_name: input_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6bdd5c-2cc7-460b-a7f0-8568e0201f8c",
   "metadata": {},
   "source": [
    "## ONNX Runtime with TensorRT Execution Provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f49f89ab-54c1-4274-a273-8396dbc8bf31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load ONNX model\n",
    "session = ort.InferenceSession(\"convnext_xxlarge.clip_laion2b_soup_ft_in1k.onnx\", providers=EP_list)\n",
    "session.set_providers(['TensorrtExecutionProvider'])\n",
    "\n",
    "# Convert data to the shape the ONNX model expects\n",
    "input_data = np.transpose(img_np, (2, 0, 1))  # Convert to (C, H, W)\n",
    "input_data = np.expand_dims(input_data, axis=0)  # Add a batch dimension\n",
    "\n",
    "input_data.shape\n",
    "\n",
    "# Get input name from the model\n",
    "input_name = session.get_inputs()[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3d074fa-313c-4f8e-b6db-3754b0ec053a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "710 ms ± 109 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# Perform inference\n",
    "output = session.run(None, {input_name: input_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5300428-3f56-4cb5-b1d7-2d1fbbe65db9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
