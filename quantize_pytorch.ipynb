{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f26e4bb-bcab-4217-a83b-0a188e6e9ac3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dnth/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "import timm\n",
    "import torch\n",
    "\n",
    "img = Image.open(urlopen(\n",
    "    'https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png'\n",
    "))\n",
    "\n",
    "model = timm.create_model('efficientvit_b0.r224_in1k', pretrained=True)\n",
    "model = model.eval()\n",
    "\n",
    "# get model specific transforms (normalization, resize)\n",
    "data_config = timm.data.resolve_model_data_config(model)\n",
    "transforms = timm.data.create_transform(**data_config, is_training=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bc1f510-6b52-4b5a-9e55-6fbb74c0b888",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# quantize model\n",
    "quantized_model = torch.quantization.quantize_dynamic(\n",
    "    model, {torch.nn.Linear}, dtype=torch.qint8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf56204a-b329-4e4d-af0f-cd7f81660b36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientVit(\n",
       "  (stem): Stem(\n",
       "    (in_conv): ConvNormAct(\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (conv): Conv2d(3, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (norm): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): Hardswish()\n",
       "    )\n",
       "    (res0): ResidualBlock(\n",
       "      (pre_norm): Identity()\n",
       "      (main): DSConv(\n",
       "        (depth_conv): ConvNormAct(\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "          (norm): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): Hardswish()\n",
       "        )\n",
       "        (point_conv): ConvNormAct(\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): Identity()\n",
       "        )\n",
       "      )\n",
       "      (shortcut): Identity()\n",
       "    )\n",
       "  )\n",
       "  (stages): Sequential(\n",
       "    (0): EfficientVitStage(\n",
       "      (blocks): Sequential(\n",
       "        (0): ResidualBlock(\n",
       "          (pre_norm): Identity()\n",
       "          (main): MBConv(\n",
       "            (inverted_conv): ConvNormAct(\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Hardswish()\n",
       "            )\n",
       "            (depth_conv): ConvNormAct(\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "              (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Hardswish()\n",
       "            )\n",
       "            (point_conv): ConvNormAct(\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): ResidualBlock(\n",
       "          (pre_norm): Identity()\n",
       "          (main): MBConv(\n",
       "            (inverted_conv): ConvNormAct(\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Hardswish()\n",
       "            )\n",
       "            (depth_conv): ConvNormAct(\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "              (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Hardswish()\n",
       "            )\n",
       "            (point_conv): ConvNormAct(\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity()\n",
       "            )\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): EfficientVitStage(\n",
       "      (blocks): Sequential(\n",
       "        (0): ResidualBlock(\n",
       "          (pre_norm): Identity()\n",
       "          (main): MBConv(\n",
       "            (inverted_conv): ConvNormAct(\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Hardswish()\n",
       "            )\n",
       "            (depth_conv): ConvNormAct(\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "              (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Hardswish()\n",
       "            )\n",
       "            (point_conv): ConvNormAct(\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): ResidualBlock(\n",
       "          (pre_norm): Identity()\n",
       "          (main): MBConv(\n",
       "            (inverted_conv): ConvNormAct(\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Hardswish()\n",
       "            )\n",
       "            (depth_conv): ConvNormAct(\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "              (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Hardswish()\n",
       "            )\n",
       "            (point_conv): ConvNormAct(\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity()\n",
       "            )\n",
       "          )\n",
       "          (shortcut): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): EfficientVitStage(\n",
       "      (blocks): Sequential(\n",
       "        (0): ResidualBlock(\n",
       "          (pre_norm): Identity()\n",
       "          (main): MBConv(\n",
       "            (inverted_conv): ConvNormAct(\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (norm): Identity()\n",
       "              (act): Hardswish()\n",
       "            )\n",
       "            (depth_conv): ConvNormAct(\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128)\n",
       "              (norm): Identity()\n",
       "              (act): Hardswish()\n",
       "            )\n",
       "            (point_conv): ConvNormAct(\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): EfficientVitBlock(\n",
       "          (context_module): ResidualBlock(\n",
       "            (pre_norm): Identity()\n",
       "            (main): LiteMSA(\n",
       "              (qkv): ConvNormAct(\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (conv): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (norm): Identity()\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (aggreg): ModuleList(\n",
       "                (0): Sequential(\n",
       "                  (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=192, bias=False)\n",
       "                  (1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), groups=12, bias=False)\n",
       "                )\n",
       "              )\n",
       "              (kernel_func): ReLU()\n",
       "              (proj): ConvNormAct(\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "          )\n",
       "          (local_module): ResidualBlock(\n",
       "            (pre_norm): Identity()\n",
       "            (main): MBConv(\n",
       "              (inverted_conv): ConvNormAct(\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (norm): Identity()\n",
       "                (act): Hardswish()\n",
       "              )\n",
       "              (depth_conv): ConvNormAct(\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "                (norm): Identity()\n",
       "                (act): Hardswish()\n",
       "              )\n",
       "              (point_conv): ConvNormAct(\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "          )\n",
       "        )\n",
       "        (2): EfficientVitBlock(\n",
       "          (context_module): ResidualBlock(\n",
       "            (pre_norm): Identity()\n",
       "            (main): LiteMSA(\n",
       "              (qkv): ConvNormAct(\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (conv): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (norm): Identity()\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (aggreg): ModuleList(\n",
       "                (0): Sequential(\n",
       "                  (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=192, bias=False)\n",
       "                  (1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), groups=12, bias=False)\n",
       "                )\n",
       "              )\n",
       "              (kernel_func): ReLU()\n",
       "              (proj): ConvNormAct(\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "          )\n",
       "          (local_module): ResidualBlock(\n",
       "            (pre_norm): Identity()\n",
       "            (main): MBConv(\n",
       "              (inverted_conv): ConvNormAct(\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (norm): Identity()\n",
       "                (act): Hardswish()\n",
       "              )\n",
       "              (depth_conv): ConvNormAct(\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "                (norm): Identity()\n",
       "                (act): Hardswish()\n",
       "              )\n",
       "              (point_conv): ConvNormAct(\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): EfficientVitStage(\n",
       "      (blocks): Sequential(\n",
       "        (0): ResidualBlock(\n",
       "          (pre_norm): Identity()\n",
       "          (main): MBConv(\n",
       "            (inverted_conv): ConvNormAct(\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (norm): Identity()\n",
       "              (act): Hardswish()\n",
       "            )\n",
       "            (depth_conv): ConvNormAct(\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256)\n",
       "              (norm): Identity()\n",
       "              (act): Hardswish()\n",
       "            )\n",
       "            (point_conv): ConvNormAct(\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "              (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): EfficientVitBlock(\n",
       "          (context_module): ResidualBlock(\n",
       "            (pre_norm): Identity()\n",
       "            (main): LiteMSA(\n",
       "              (qkv): ConvNormAct(\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (conv): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (norm): Identity()\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (aggreg): ModuleList(\n",
       "                (0): Sequential(\n",
       "                  (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
       "                  (1): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), groups=24, bias=False)\n",
       "                )\n",
       "              )\n",
       "              (kernel_func): ReLU()\n",
       "              (proj): ConvNormAct(\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "          )\n",
       "          (local_module): ResidualBlock(\n",
       "            (pre_norm): Identity()\n",
       "            (main): MBConv(\n",
       "              (inverted_conv): ConvNormAct(\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (norm): Identity()\n",
       "                (act): Hardswish()\n",
       "              )\n",
       "              (depth_conv): ConvNormAct(\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                (norm): Identity()\n",
       "                (act): Hardswish()\n",
       "              )\n",
       "              (point_conv): ConvNormAct(\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "          )\n",
       "        )\n",
       "        (2): EfficientVitBlock(\n",
       "          (context_module): ResidualBlock(\n",
       "            (pre_norm): Identity()\n",
       "            (main): LiteMSA(\n",
       "              (qkv): ConvNormAct(\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (conv): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (norm): Identity()\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (aggreg): ModuleList(\n",
       "                (0): Sequential(\n",
       "                  (0): Conv2d(384, 384, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=384, bias=False)\n",
       "                  (1): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), groups=24, bias=False)\n",
       "                )\n",
       "              )\n",
       "              (kernel_func): ReLU()\n",
       "              (proj): ConvNormAct(\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "          )\n",
       "          (local_module): ResidualBlock(\n",
       "            (pre_norm): Identity()\n",
       "            (main): MBConv(\n",
       "              (inverted_conv): ConvNormAct(\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (norm): Identity()\n",
       "                (act): Hardswish()\n",
       "              )\n",
       "              (depth_conv): ConvNormAct(\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                (norm): Identity()\n",
       "                (act): Hardswish()\n",
       "              )\n",
       "              (point_conv): ConvNormAct(\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "            (shortcut): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (head): ClassifierHead(\n",
       "    (in_conv): ConvNormAct(\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (conv): Conv2d(128, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (act): Hardswish()\n",
       "    )\n",
       "    (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "    (classifier): Sequential(\n",
       "      (0): DynamicQuantizedLinear(in_features=1024, out_features=1280, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "      (1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (2): Hardswish()\n",
       "      (3): Dropout(p=0.0, inplace=False)\n",
       "      (4): DynamicQuantizedLinear(in_features=1280, out_features=1000, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantized_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f74790a4-388e-4ae2-8bac-58b67f380650",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.9 ms ± 305 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "output = model(transforms(img).unsqueeze(0))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23f9d3fb-1f89-4cc0-b65e-33cd475b6630",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.8 ms ± 474 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "output = quantized_model(transforms(img).unsqueeze(0))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c8a9544-b25a-4b88-b7ae-21b7a60176ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (MB): 13.097017288208008\n",
      "Size (MB): 5.68641471862793\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "def print_size_of_model(model):\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    print('Size (MB):', os.path.getsize(\"temp.p\")/(1024*1024))\n",
    "    os.remove('temp.p')\n",
    "\n",
    "print_size_of_model(model)\n",
    "print_size_of_model(quantized_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab8fff22-a3c9-4d5a-b8fa-9d806c21a070",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 1 ERROR ========================\n",
      "ERROR: missing-standard-symbolic-function\n",
      "=========================================\n",
      "Exporting the operator 'quantized::linear_dynamic' to ONNX opset version 16 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub: https://github.com/pytorch/pytorch/issues.\n",
      "None\n",
      "<Set verbose=True to see more details>\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "UnsupportedOperatorError",
     "evalue": "Exporting the operator 'quantized::linear_dynamic' to ONNX opset version 16 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub: https://github.com/pytorch/pytorch/issues.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnsupportedOperatorError\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01monnx\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquantized_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrand\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequires_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                 \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mefficientvit_b0.r224_in1k_pytorch_quantized.onnx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mdo_constant_folding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                 \u001b[49m\u001b[43minput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                 \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutput\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                               \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutput\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch-edge/lib/python3.10/site-packages/torch/onnx/utils.py:506\u001b[0m, in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;129m@_beartype\u001b[39m\u001b[38;5;241m.\u001b[39mbeartype\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexport\u001b[39m(\n\u001b[1;32m    190\u001b[0m     model: Union[torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule, torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mScriptModule, torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mScriptFunction],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    206\u001b[0m     export_modules_as_functions: Union[\u001b[38;5;28mbool\u001b[39m, Collection[Type[torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    207\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Exports a model into ONNX format.\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \n\u001b[1;32m    210\u001b[0m \u001b[38;5;124;03m    If ``model`` is not a :class:`torch.jit.ScriptModule` nor a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;124;03m            All errors are subclasses of :class:`errors.OnnxExporterError`.\u001b[39;00m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 506\u001b[0m     \u001b[43m_export\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopset_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_constant_folding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_opsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_opsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch-edge/lib/python3.10/site-packages/torch/onnx/utils.py:1548\u001b[0m, in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions)\u001b[0m\n\u001b[1;32m   1545\u001b[0m     dynamic_axes \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1546\u001b[0m _validate_dynamic_axes(dynamic_axes, model, input_names, output_names)\n\u001b[0;32m-> 1548\u001b[0m graph, params_dict, torch_out \u001b[38;5;241m=\u001b[39m \u001b[43m_model_to_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1549\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1550\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1551\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1552\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1553\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1554\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1555\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_do_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfixed_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfixed_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1561\u001b[0m \u001b[38;5;66;03m# TODO: Don't allocate a in-memory string for the protobuf\u001b[39;00m\n\u001b[1;32m   1562\u001b[0m defer_weight_export \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1563\u001b[0m     export_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _exporter_states\u001b[38;5;241m.\u001b[39mExportTypes\u001b[38;5;241m.\u001b[39mPROTOBUF_FILE\n\u001b[1;32m   1564\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch-edge/lib/python3.10/site-packages/torch/onnx/utils.py:1117\u001b[0m, in \u001b[0;36m_model_to_graph\u001b[0;34m(model, args, verbose, input_names, output_names, operator_export_type, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\u001b[0m\n\u001b[1;32m   1114\u001b[0m params_dict \u001b[38;5;241m=\u001b[39m _get_named_param_dict(graph, params)\n\u001b[1;32m   1116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1117\u001b[0m     graph \u001b[38;5;241m=\u001b[39m \u001b[43m_optimize_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_disable_torch_constant_prop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_disable_torch_constant_prop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfixed_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfixed_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1124\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1126\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1128\u001b[0m     torch\u001b[38;5;241m.\u001b[39monnx\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch IR graph at exception: \u001b[39m\u001b[38;5;124m\"\u001b[39m, graph)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch-edge/lib/python3.10/site-packages/torch/onnx/utils.py:665\u001b[0m, in \u001b[0;36m_optimize_graph\u001b[0;34m(graph, operator_export_type, _disable_torch_constant_prop, fixed_batch_size, params_dict, dynamic_axes, input_names, module)\u001b[0m\n\u001b[1;32m    662\u001b[0m     _C\u001b[38;5;241m.\u001b[39m_jit_pass_onnx_set_dynamic_input_shape(graph, dynamic_axes, input_names)\n\u001b[1;32m    663\u001b[0m _C\u001b[38;5;241m.\u001b[39m_jit_pass_onnx_lint(graph)\n\u001b[0;32m--> 665\u001b[0m graph \u001b[38;5;241m=\u001b[39m \u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jit_pass_onnx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    666\u001b[0m _C\u001b[38;5;241m.\u001b[39m_jit_pass_onnx_lint(graph)\n\u001b[1;32m    667\u001b[0m _C\u001b[38;5;241m.\u001b[39m_jit_pass_lint(graph)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch-edge/lib/python3.10/site-packages/torch/onnx/utils.py:1901\u001b[0m, in \u001b[0;36m_run_symbolic_function\u001b[0;34m(graph, block, node, inputs, env, operator_export_type)\u001b[0m\n\u001b[1;32m   1897\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m namespace \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monnx\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1898\u001b[0m         \u001b[38;5;66;03m# Clone node to trigger ONNX shape inference\u001b[39;00m\n\u001b[1;32m   1899\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m graph_context\u001b[38;5;241m.\u001b[39mop(op_name, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mattrs, outputs\u001b[38;5;241m=\u001b[39mnode\u001b[38;5;241m.\u001b[39moutputsSize())  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m-> 1901\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mUnsupportedOperatorError(\n\u001b[1;32m   1902\u001b[0m         symbolic_function_name,\n\u001b[1;32m   1903\u001b[0m         opset_version,\n\u001b[1;32m   1904\u001b[0m         symbolic_function_group\u001b[38;5;241m.\u001b[39mget_min_supported()\n\u001b[1;32m   1905\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m symbolic_function_group\n\u001b[1;32m   1906\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1907\u001b[0m     )\n\u001b[1;32m   1909\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m:\n\u001b[1;32m   1910\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m operator_export_type \u001b[38;5;241m==\u001b[39m _C_onnx\u001b[38;5;241m.\u001b[39mOperatorExportTypes\u001b[38;5;241m.\u001b[39mONNX_FALLTHROUGH:\n",
      "\u001b[0;31mUnsupportedOperatorError\u001b[0m: Exporting the operator 'quantized::linear_dynamic' to ONNX opset version 16 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub: https://github.com/pytorch/pytorch/issues."
     ]
    }
   ],
   "source": [
    "import torch.onnx\n",
    "torch.onnx.export(quantized_model,\n",
    "                 torch.rand(1, 3, 224, 224, requires_grad=True),\n",
    "                 \"efficientvit_b0.r224_in1k_pytorch_quantized.onnx\",\n",
    "                 export_params=True,\n",
    "                 opset_version=16,\n",
    "                 do_constant_folding=True,\n",
    "                 input_names=['input'],\n",
    "                 output_names=['output'], \n",
    "                 dynamic_axes={'input' : {0 : 'batch_size'},   \n",
    "                               'output' : {0 : 'batch_size'}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19777a5-006f-499f-b140-c5a8ec09228f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
